{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control of the COCO annotations file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycocotools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-970e206f3acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolorsys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmaskUtils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycocotools'"
     ]
    }
   ],
   "source": [
    "#Import librairies\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import colorsys\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import skimage.io\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "from geolabel_maker import tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of a dedicated class\n",
    "It inherits the COCO class from pycocotools.coco.\n",
    "It is used to read the annotations file in COCO format and extract information on the ground truth game and view it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Dataset for visualization\n",
    "class DataViewer(COCO) :\n",
    "    def __init__(self, annotation_file, dir_tiles, zoom ) :\n",
    "        '''\n",
    "        annotion_file for specified zoom (str)\n",
    "        dir_tiles directory where Images/labels folders are (str)\n",
    "        zoom (str)\n",
    "        '''\n",
    "        COCO.__init__(self,annotation_file)\n",
    "        self.annotation_file = annotation_file\n",
    "        self.dir_image, self.dir_label = tiles.get_tiles_directories(dir_tiles)\n",
    "        self.dir_image = self.dir_image / zoom\n",
    "        self.dir_label = self.dir_label / zoom\n",
    "\n",
    "\n",
    "    '''\n",
    "    Part 1 : Information from annotations file\n",
    "\n",
    "    '''      \n",
    "    def infos(self) :\n",
    "        '''\n",
    "        return informations in \"infos\" section of annotations file\n",
    "        '''   \n",
    "        print(\"Informations\")\n",
    "        print(\"============\")\n",
    "        self.info()\n",
    "        print(\"____________\")\n",
    "        print()\n",
    "\n",
    "    def categories(self):\n",
    "        '''\n",
    "        return informations in  \"categories\" of annotations file\n",
    "        '''  \n",
    "        print(\"Categories\")\n",
    "        print(\"============\")\n",
    "        print(\"Numbers of categegory in this dataset\",len(self.dataset['categories']))\n",
    "        for cat in self.dataset['categories'] :\n",
    "            print( \"Supercategory \", cat['supercategory'])\n",
    "            print( \"Category \", cat['name'])\n",
    "            print( \"Class ID \", cat['id'])\n",
    "        print(\"____________\")    \n",
    "        print()\n",
    "\n",
    "    def images(self,limit=10) :\n",
    "        ''' \n",
    "        limit : (int) number of images informations to show. Default is 10.\n",
    "        return number of images\n",
    "        and the list of images\n",
    "        '''\n",
    "        print(\"Images\")\n",
    "        print(\"============\")\n",
    "        print(\"Number of images in the Dataset : \", len(self.dataset['images']))\n",
    "        print(\"____________\")\n",
    "        if limit>0 :\n",
    "            print(f'{limit} first images of the dataset')\n",
    "            for im in self.dataset['images'][:limit] :\n",
    "                print(im)\n",
    "        print(\"____________\")\n",
    "        print()\n",
    "\n",
    "\n",
    "    def image_with_class (self,cat_id) :  \n",
    "        '''\n",
    "        cat_id : (int) id of the class id of interest\n",
    "        return a list of image_id that contains object of catID\n",
    "        '''                \n",
    "        for i in range (len (self.dataset['categories'])) :\n",
    "            if self.dataset['categories'][i]['id']==cat_id :\n",
    "                class_name=self.dataset['categories'][i]['name']\n",
    "               \n",
    "        images_id=[]\n",
    "        for i in range (len(self.dataset['annotations'])) :       \n",
    "            if self.dataset['annotations'][i]['category_id'] == cat_id :\n",
    "                images_id.append(self.dataset['annotations'][i]['image_id'])\n",
    "        print(\"{} objects in the {} images dataset with Category {} ({})\".format(len(images_id),len(self.dataset['images']),class_name,cat_id))\n",
    "        \n",
    "        return images_id \n",
    "    \n",
    "    \n",
    "    def cat_stat (self, cat_id) :\n",
    "        '''\n",
    "        cat_id : (int) id of the class id of interest\n",
    "        return a list of image_id that contains object of cat_id\n",
    "        '''\n",
    "        list_cat=self.image_with_class(cat_id)\n",
    "        \n",
    "        for i in range (len (self.dataset['categories'])) :\n",
    "            if self.dataset['categories'][i]['id']==cat_id :\n",
    "                class_name=self.dataset['categories'][i]['name']\n",
    "        \n",
    "        \n",
    "        dict_cat={}\n",
    "        for item in list_cat :\n",
    "            if item not in dict_cat :\n",
    "                dict_cat[item]=1\n",
    "            else :\n",
    "                dict_cat[item]+=1\n",
    "\n",
    "        print(f'{len(dict_cat.keys())} images on {len(self.dataset[\"images\"])} with category {class_name} ({cat_id})')\n",
    "        print(f'{np.mean(list(dict_cat.values()))} objects of category {class_name} ({cat_id}) in average per image with these category')\n",
    "        print(f'maximum : {np.max(list(dict_cat.values()))} objects detected of category {class_name} ({cat_id})')\n",
    "        print(f'images with maximum detection of category {class_name} ({cat_id}) : {[im for im, detection in dict_cat.items() if detection == np.max(list(dict_cat.values()))]}')\n",
    "        return dict_cat\n",
    "    \n",
    "    def img_annotation(self,image_id) :\n",
    "        annotations=[]\n",
    "        print(\"Annotations for image_id \", image_id)\n",
    "        for i in range (len(self.dataset['annotations'])) :\n",
    "            if self.dataset['annotations'][i]['image_id'] == image_id :\n",
    "                  annotation= self.dataset['annotations'][i]\n",
    "                  print(annotation)\n",
    "                  annotations.append(annotation)\n",
    "        if len(annotations)== 0 :\n",
    "            print(\"No annotation to show\")\n",
    "        return annotations\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    Part 2 : Images, Masks, BBoxes and Class Name\n",
    "    '''   \n",
    "    # IMAGE   \n",
    "    def load_image(self,image_id) : \n",
    "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        for i in range (len(self.dataset['images'])) :\n",
    "            if self.dataset['images'][i]['id'] == image_id :\n",
    "                image = skimage.io.imread(self.dir_image/self.dataset['images'][i]['file_name'])\n",
    "        \n",
    "        return image\n",
    "\n",
    "\n",
    "    # MASK \n",
    "    def load_mask(self,image_id) :\n",
    "        \"\"\"Load instance masks for the given image.\n",
    "\n",
    "        image_id : (int) id of the image of interest\n",
    "\n",
    "        Returns:\n",
    "            masks: A bool array of shape [height, width, instance count] with\n",
    "                a binary mask per instance.\n",
    "            class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range (len(self.dataset['images'])) :\n",
    "            if self.dataset['images'][i]['id'] == image_id :\n",
    "                 height=self.dataset['images'][i]['height']\n",
    "                 width=self.dataset['images'][i]['width']\n",
    "\n",
    "        annotations=[]\n",
    "        for i in range (len(self.dataset['annotations'])) :\n",
    "            if self.dataset['annotations'][i]['image_id'] == image_id :\n",
    "                  annotations.append(self.dataset['annotations'][i])\n",
    "\n",
    "        instance_masks = []\n",
    "        class_ids = []\n",
    "        for ann in annotations :\n",
    "            class_id=ann['category_id']\n",
    "\n",
    "            if class_id  :\n",
    "                m = self.annToMask(ann, height,width)\n",
    "\n",
    "                if m.max() < 1:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                instance_masks.append(m)\n",
    "                class_ids.append(class_id)\n",
    "          # Pack instance masks into an array\n",
    "        if len(class_ids)>0:\n",
    "          mask = np.stack(instance_masks, axis=2)\n",
    "          class_ids = np.array(class_ids, dtype=np.int32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return mask,class_ids\n",
    "\n",
    "\n",
    "    def annToRLE(self, ann, height, width):\n",
    "        \"\"\"\n",
    "        adapted form https://github.com/matterport/Mask_RCNN\n",
    "        Convert annotation which can be polygons, uncompressed RLE to RLE.\n",
    "        :return: binary mask (numpy 2D array)\n",
    "        \"\"\"\n",
    "        segm = ann['segmentation']\n",
    "        if isinstance(segm, list):\n",
    "            # polygon -- a single object might consist of multiple parts\n",
    "            # we merge all parts into one mask rle code\n",
    "            rles = maskUtils.frPyObjects(segm, height, width)\n",
    "            rle = maskUtils.merge(rles)\n",
    "        elif isinstance(segm['counts'], list):\n",
    "            # uncompressed RLE\n",
    "            rle = maskUtils.frPyObjects(segm, height, width)\n",
    "        else:\n",
    "            # rle\n",
    "            rle = ann['segmentation']\n",
    "        return rle\n",
    "\n",
    "    def annToMask(self, ann, height, width):\n",
    "        \"\"\"\n",
    "        adapted form https://github.com/matterport/Mask_RCNN\n",
    "        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n",
    "        :return: binary mask (numpy 2D array)\n",
    "        \"\"\"\n",
    "        rle = self.annToRLE(ann, height, width)\n",
    "        m = maskUtils.decode(rle)\n",
    "        return m\n",
    "\n",
    "    # BBOXES\n",
    "    def load_bbox(self,image_id) :\n",
    "        \"\"\"Load bboxes for the given image.\n",
    "\n",
    "        image_id : (int) id of the image of interest\n",
    "\n",
    "        Returns:\n",
    "            bboxes : [num_instance, (x, y, W, H) ]\n",
    "        \"\"\"\n",
    "        bboxes=[]\n",
    "        for i in range (len(self.dataset['annotations'])) :\n",
    "            if self.dataset['annotations'][i]['image_id'] == image_id :\n",
    "                bbox=self.dataset['annotations'][i]['bbox']\n",
    "                bboxes.append(bbox)\n",
    "        return np.multiply(bboxes, 1).astype(dtype=\"int32\")\n",
    "\n",
    "        # CLASS NAME\n",
    "    def class_names(self) :\n",
    "        \"\"\"\n",
    "        Returns list of category name.\n",
    "        \"\"\"\n",
    "        class_names=['BG']\n",
    "        for i in range (len(self.dataset['categories'])) :   \n",
    "            class_name= self.dataset['categories'][i][\"name\"]\n",
    "            class_names.append(class_name)\n",
    "        return class_names\n",
    "    \n",
    "\n",
    "    '''\n",
    "    Part 3 : Visualisations\n",
    "    '''        \n",
    "    # IMAGE/LABEL \n",
    "    def show_image_label(self,image_id, label=False, bbox=False, figsize=(16,16)):\n",
    "        '''\n",
    "        Show image from dataset, label from dataset and bbox from annotations\n",
    "        image_id : (int) id of the image of interest\n",
    "        '''\n",
    "        true_id= 0\n",
    "        for i in range (len(self.dataset['images']) ):\n",
    "            if self.dataset['images'][i]['id'] == image_id :\n",
    "                     true_id = i\n",
    "\n",
    "        image=Image.open(self.dir_image/self.dataset['images'][true_id]['file_name'])\n",
    "        if label==False :\n",
    "            figure, axis = plt.subplots(1,1,figsize=figsize,constrained_layout=True)\n",
    "            axis.imshow(image)\n",
    "            if bbox== True :\n",
    "                bboxes=self.load_bbox(image_id)\n",
    "                N=bboxes.shape[0]\n",
    "                color=self.random_colors(N)\n",
    "                for bbox in bboxes :\n",
    "                    axis.add_artist(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3],edgecolor = random.choice(color),fill = False )) \n",
    "            figure.suptitle(self.dataset['images'][true_id]['file_name'],y=0.7)\n",
    "            axis.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        if label==True :\n",
    "            lab=Image.open(self.dir_label/self.dataset['images'][true_id]['file_name'])\n",
    "            figure, axis = plt.subplots(1,3,figsize=figsize,constrained_layout=True)\n",
    "            axis[0].imshow(image)\n",
    "            axis[1].imshow(lab,cmap=\"gray\")\n",
    "            axis[2].imshow(image)\n",
    "            axis[2].imshow(lab, alpha=0.5)\n",
    "            if bbox== True :\n",
    "                bboxes=self.load_bbox(image_id)\n",
    "                N=bboxes.shape[0]\n",
    "                color=self.random_colors(N)\n",
    "                for bbox in bboxes :\n",
    "                    axis[2].add_artist(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3],edgecolor = random.choice(color),fill = False )) \n",
    "            axis[0].axis('off')\n",
    "            axis[1].axis('off')\n",
    "            axis[2].axis('off')\n",
    "            figure.suptitle(\"Images/labels {}\".format(self.dataset['images'][true_id]['file_name']), y=0.7)\n",
    "            plt.show()\n",
    "            \n",
    "\n",
    "    #ANNOTATIONS \n",
    "    def display_all(self,image, boxes, masks, class_ids, class_names, title=\"\",figsize=(16, 16), ax=None):\n",
    "        \"\"\"\n",
    "         adapted form https://github.com/matterport/Mask_RCNN\n",
    "         boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
    "         masks: [height, width, num_instances]\n",
    "         class_ids: [num_instances]\n",
    "         class_names: list of class names of the dataset\n",
    "         figsize: (optional) the size of the image.\n",
    "        \"\"\"\n",
    "        # Number of instances\n",
    "        N = masks.shape[-1]\n",
    "        if not N:\n",
    "            print(\"\\n*** No instances to display *** \\n\")\n",
    "        else:\n",
    "            assert   masks.shape[-1] == class_ids.shape[0]\n",
    "\n",
    "        if not ax:\n",
    "            _, ax = plt.subplots(1, figsize=figsize)\n",
    " \n",
    "        # Generate random colors\n",
    "        colors = self.random_colors(N)\n",
    "\n",
    "        # Show area outside image boundaries.\n",
    "        height, width = image.shape[:2]\n",
    "        ax.set_ylim(height + 10, -10)\n",
    "        ax.set_xlim(-10, width + 10)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(title)\n",
    "\n",
    "        masked_image = image.astype(np.uint32).copy()\n",
    "        for i in range(N):\n",
    "            color = colors[i]\n",
    "\n",
    "            # Bounding box\n",
    "            if not np.any(boxes[i]):\n",
    "                # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "                continue\n",
    "            y1, x1, y2, x2 = boxes[i]\n",
    "            p = matplotlib.patches.Rectangle((y1, x1), y2, x2, linewidth=2,\n",
    "                                  alpha=0.7, linestyle=\"dashed\",\n",
    "                                  edgecolor=color, facecolor='none')\n",
    "            ax.add_patch(p)\n",
    "\n",
    "            # Label\n",
    "            class_id = class_ids[i]\n",
    "            \n",
    "            label = class_names[class_id]\n",
    "            \n",
    "            caption = \"{}\".format(label) \n",
    "            ax.text(x1, y1 + 8, caption,\n",
    "                    color='w', size=11, backgroundcolor=\"none\")\n",
    "\n",
    "            # Mask\n",
    "            mask = masks[:, :, i]\n",
    "            masked_image =self.apply_mask(masked_image, mask, color)\n",
    "\n",
    "            # Mask Polygon\n",
    "            # Pad to ensure proper polygons for masks that touch image edges.\n",
    "            padded_mask = np.zeros(\n",
    "                (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
    "            padded_mask[1:-1, 1:-1] = mask\n",
    "            contours = find_contours(padded_mask, 0.5)\n",
    "            for verts in contours:\n",
    "                # Subtract the padding and flip (y, x) to (x, y)\n",
    "                verts = np.fliplr(verts) - 1\n",
    "                p = matplotlib.patches.Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
    "                ax.add_patch(p)\n",
    "        ax.imshow(masked_image.astype(np.uint8))\n",
    "        plt.show() \n",
    "\n",
    "    def display_top_masks(self,image, mask, class_ids, class_names, limit=4):\n",
    "        \"\"\"\n",
    "        adapted form https://github.com/matterport/Mask_RCNN\n",
    "        Display the given image and the top few class masks.\"\"\"\n",
    "        to_display = []\n",
    "        titles = []\n",
    "        to_display.append(image)\n",
    "        titles.append(\"H x W={}x{}\".format(image.shape[0], image.shape[1]))\n",
    "        # Pick top prominent classes in this image\n",
    "        unique_class_ids = np.unique(class_ids)\n",
    "        mask_area = [np.sum(mask[:, :, np.where(class_ids == i)[0]])\n",
    "                 for i in unique_class_ids]\n",
    "        top_ids = [v[0] for v in sorted(zip(unique_class_ids, mask_area),\n",
    "                                    key=lambda r: r[1], reverse=True) if v[1] > 0]\n",
    "        # Generate images and titles\n",
    "        for i in range(limit):\n",
    "            class_id = top_ids[i] if i < len(top_ids) else -1\n",
    "        # Pull masks of instances belonging to the same class.\n",
    "            m = mask[:, :, np.where(class_ids == class_id)[0]]\n",
    "            m = np.sum(m * np.arange(1, m.shape[-1] + 1), -1)\n",
    "            to_display.append(m)\n",
    "            titles.append(class_names[class_id] if class_id != -1 else \"-\")\n",
    "        self.display_images(to_display, titles=titles, cols=limit + 1, cmap=\"Blues_r\")\n",
    "\n",
    "    def display_images(self,images, titles=None, cols=4, cmap=None, norm=None,\n",
    "           interpolation=None):\n",
    "        \"\"\"Display the given set of images, optionally with titles.\n",
    "        images: list or array of image tensors in HWC format.\n",
    "        titles: optional. A list of titles to display with each image.\n",
    "        cols: number of images per row\n",
    "        cmap: Optional. Color map to use. For example, \"Blues\".\n",
    "        norm: Optional. A Normalize instance to map values to colors.\n",
    "        interpolation: Optional. Image interporlation to use for display.\n",
    "        \"\"\"\n",
    "        titles = titles if titles is not None else [\"\"] * len(images)\n",
    "        rows = len(images) // cols + 1\n",
    "        plt.figure(figsize=(14, 14 * rows // cols))\n",
    "        i = 1\n",
    "        for image, title in zip(images, titles):\n",
    "            plt.subplot(rows, cols, i)\n",
    "            plt.title(title, fontsize=9)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(image.astype(np.uint8), cmap=cmap,\n",
    "                       norm=norm, interpolation=interpolation)\n",
    "            i += 1\n",
    "        plt.show()\n",
    "\n",
    "    def random_colors(self,N, bright=True):\n",
    "        \"\"\"\n",
    "        form https://github.com/matterport/Mask_RCNN\n",
    "        Generate random colors.\n",
    "        To get visually distinct colors, generate them in HSV space then\n",
    "        convert to RGB.\n",
    "        \"\"\"\n",
    "        brightness = 1.0 if bright else 0.7\n",
    "        hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "        colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "        random.shuffle(colors)\n",
    "        return colors\n",
    "\n",
    "    def apply_mask(self,image, mask, color, alpha=0.5):\n",
    "        \"\"\"\n",
    "        form https://github.com/matterport/Mask_RCNN\n",
    "        Apply the given mask to the image.\n",
    "        \"\"\"\n",
    "        for c in range(3):\n",
    "            image[:, :, c] = np.where(mask == 1,\n",
    "                                      image[:, :, c] *\n",
    "                                      (1 - alpha) + alpha * color[c] * 255,\n",
    "                                      image[:, :, c])\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display data set information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "coco_file = \"annotations.json\"\n",
    "dir_tiles = \"../data/tiles/\"\n",
    "zoom = \"15\"\n",
    "\n",
    "#Initialisation du jeu de données\n",
    "Data=DataViewer(coco_file, dir_tiles, zoom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informations générales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage des informations de bases sur le jeu de données\n",
    "print(\"____________\")\n",
    "Data.infos()           \n",
    "Data.categories()\n",
    "Data.images(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regardons plus en profondeur :\n",
    "Nous pouvons regarder de manière plus approfondies les informations contenues dans le fichier annotations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quels sont les catégories d'objets présentes dans notre jeu de données ?\n",
    "Data.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combien d'objets de la classe \"vegetation\" sont référencés dans l'ensemble de notre jeu de données  ? \n",
    "# La classe vegetation a l'identifiant 1.\n",
    "list_cat_1=Data.image_with_class(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combien d'objets de la classe \"buildings\" sont référencés dans l'ensemble de notre jeu de données  ? \n",
    "# La classe buildings a l'identifiant 2.\n",
    "list_cat_2=Data.image_with_class(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment sont distribués ces objets dans notre jeu de données ? \n",
    "# vegetation :\n",
    "distribution_vegetation=Data.cat_stat (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buildings\n",
    "distribution_buildings=Data.cat_stat (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelles sont les annotations correspondant à l'image 1 ?\n",
    "ann_1=Data.img_annotation(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation du jeu de données :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des couples Images/Labels crées par Geolabel_maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation des labels associés à chaque image et bboxes de l'annotation si bbox==True\n",
    "# Un subbplot pour l'image, un subplot pour le label et un subplot Image/label/bbox\n",
    "# Dans l'image choisie des batiments et de la végétalisation ont été labelisés. Les différentes bboxes issues de l'annotations apparaissent de couleur différente pour chaque objet.\n",
    "Data.show_image_label(1,label=True, bbox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des couples Images et Annotations générées par Geolabel_maker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation des masques associés à chaque image. Un subplot par catégorie, Un dégradé de couleur par objet.\n",
    "# Dans notre exemple ,nous avons deux catégories. Nous limitons donc l'affichage à 2 categories.\n",
    "\n",
    "#exemple avec l'image dont l'id est 2.\n",
    "image = Data.load_image(2)\n",
    "mask, class_ids= Data.load_mask(2)\n",
    "bbox=Data.load_bbox(2)\n",
    "Data.display_top_masks(image, mask, class_ids, Data.class_names(),limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De même la fonction display_all permet d'afficher les masks et bboxes du fichier annotation.\n",
    "Data.display_all(image, bbox, mask,class_ids, Data.class_names(),figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
